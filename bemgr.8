.\"Boost Software License - Version 1.0 - August 17th, 2003
.\"
.\"Permission is hereby granted, free of charge, to any person or organization
.\"obtaining a copy of the software and accompanying documentation covered by
.\"this license (the "Software") to use, reproduce, display, distribute,
.\"execute, and transmit the Software, and to prepare derivative works of the
.\"Software, and to permit third-parties to whom the Software is furnished to
.\"do so, all subject to the following:
.\"
.\"The copyright notices in the Software and this entire statement, including
.\"the above license grant, this restriction and the following disclaimer,
.\"must be included in all copies of the Software, in whole or in part, and
.\"all derivative works of the Software, unless such copies or derivative
.\"works are solely in the form of machine-executable object code generated by
.\"a source language processor.
.\"
.\"THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
.\"IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
.\"FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
.\"SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
.\"FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
.\"ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
.\"DEALINGS IN THE SOFTWARE.
.Dd April 6, 2025
.Dt BEMGR 8
.Os
.Sh NAME
.Nm bemgr
.Nd Program for managing ZFS boot environments
.Sh SYNOPSIS
.Nm bemgr
.Fl \-help
.Nm
.Cm activate
.Ar beName
.Nm
.Cm create
.Op Fl e Ar beName | Fl e Ar beName@snapshot
.Ar newBEName
.Nm
.Cm create
.Ar beName@snapshot
.Nm
.Cm destroy
.Op Fl k
.Op Fl n
.Op Fl F
.Ar beName
.Nm
.Cm destroy
.Op Fl n
.Op Fl F
.Ar beName@snapshot
.Nm
.Cm export
.Op Fl k
.Op Fl v
.Ar sourceBE
.Nm
.Cm import
.Op Fl v
.Ar targetBE
.Nm
.Cm list
.Op Fl a
.Op Fl H
.Op Fl s
.Nm
.Cm mount
.Ar beName
.Ar mountpoint
.Nm
.Cm rename
.Ar origBEName
.Ar newBEName
.Nm
.Cm umount
.Op Fl f
.Ar beName
.Nm
.Cm unmount
.Op Fl f
.Ar beName
.Sh DESCRIPTION
The
.Nm
program is used to manage ZFS boot environments.
.Pp
A boot environment is a zfs dataset which mounts at
.Pa /
and contains the OS.
By creating a new boot environment by cloning an existing one, it makes it
possible to save the current state of the OS when upgrading and easily restore
it if the upgrade fails.
.Pp
FreeBSD documentation on boot environments:
.Lk https://wiki.freebsd.org/BootEnvironments
.Pp
zfsbootmenu documentation on boot environments:
.Lk https://docs.zfsbootmenu.org/en/v3.0.x/general/bootenvs\-and\-you.html
.Pp
The typical layout for zfs boot environments would be something like
.Bd -literal
zroot/ROOT/default
zroot/ROOT/2025\-03\-29_before_update
zroot/ROOT/2025\-04\-17_before_update
zroot/ROOT/testing_some_package
.Ed
.Pp
The pool name of course does not matter, and the parent dataset doesn't need to
be named
.Pa ROOT Ns ,
but it's common practice. Each dataset under the parent dataset is a separate
boot environment. Each boot environment dataset contains the root of the
filesystem, allowing you to have separate copies, making rolling back changes
easy. And since the combination of
.Sy zfs\ snap
and
.Sy zfs\ clone
makes it so that data is shared across datasets until it's changed, the space
requirements are much less than they would be if the boot environments were
fully independent copies.
So, COW (copy\-on\-write) comes to the rescue as it often does with ZFS.
.Pp
Each boot environment should have its
.Em mountpoint
property set to
.Pa / Ns ,
and its
.Em canmount
property should be set to
.Em noauto
so that it does not get mounted automatically.
The
.Em bootfs
property on the pool will then tell the boot manager which boot environment to
.No mount as root by default (e.g. Sy bootfs=zroot/ROOT/default Ns ).
.Pp
.Nm
expects that boot environments will not have any child datasets.
Other datasets can of course be mounted on top of the boot environment, but
they should be placed elsewhere in the pool and not under the datasets for the
boot environments.
.Pp
Directories that should be separate from the OS and shared across boot
environments \- such as
.Pa /home
or
.Pa /var/log
\- then have their own datasets which mount on top of the boot environment.
So, when you switch between boot environments, those directories are unchanged.
.Pp
So, common usage would be to run
.Sy bemgr\ create
to create a new boot environment from the currently active boot environment
before making large changes to the OS (e.g. updating the packages which are
installed or doing a major OS upgrade).
That way, if something goes wrong, it's possible to restore the previous state
of the OS by switching to the previous boot environment.
.Pp
.Sy bemgr\ activate
is used to switch to a different boot environment the next time that the
computer reboots (and boot managers will typically give the ability to manually
select a boot environment other than the default to boot from).
.Sh COMMANDS
.Bl -tag -width 0
.It Xo
.Fl \-help
.Xc
Prints out the list of commands.
If used following one of the commands, it will print out further information
specific to that command.
.It Xo
.Cm activate
.Ar beName
.Xc
This sets the given boot environment as the one to boot the next time that the
computer is rebooted.
.Pp
In more detail:
.Bl -enum -width 1
.It
If the dataset of the BE is a clone, then it is promoted.
.It
The dataset's
.Em canmount
property is set to
.Em noauto
(which it should be already, but if someone has been messing with the BE
datasets manually, it might not be).
.It
The dataset's
.Em mountpoint
property is set to
.Pa /
(which it should be already, but if someone has been messing with the BE
datasets manually, it might not be).
.It
The
.Em bootfs
zpool property is set to the dataset for the given boot environment so that the
boot manager knows to now boot it by default.
.El
.It Xo
.Cm create
.Op Fl e Ar beName | Fl e Ar beName@snapshot
.Ar newBEName
.Xc
This creates a new boot environment from an existing boot environment.
.Pp
If
.Fl e
is not used, then the new BE is created from the currently active BE.
For instance, if
.Pa default
were the current BE, and the parent of the BE datasets is
.Pa zroot/ROOT Ns ,
then
.Sy bemgr\ create\ foo
will take a snapshot of
.Pa zroot/ROOT/default
and clone that snapshot to create
.Pa zroot/ROOT/foo Ns .
.Pp
If
.Fl e
.Ar beName
is used, then the new BE is created by taking a snapshot of the BE provided to
.Fl e
rather than the currently active BE.
It is then cloned just like would have occurred if the snapshot had been from
the current BE. For instance,
.Sy bemgr\ create\ \-e\ foo\ bar
would create a snapshot of
.Pa zroot/ROOT/foo
and clone it to create
.Pa zroot/ROOT/bar
regardless of which BE was the active one.
.Pp
If
.Fl e
.Ar beName@snapshot
is used, then instead of taking the snapshot of a BE and cloning it, the given
snapshot is cloned.
So, if
.Pa zroot/ROOT/foo
had the snapshot
.Pa zroot/ROOT/foo@2025\-04\-02_update Ns ,
.Sy bemgr\ \-e\ foo@2025\-04\-02_update\ bar
would clone
.Pa zroot/ROOT/foo@2025\-04\-02_update
and create
.Pa zroot/ROOT/bar Ns .
.Pp
The newly created boot environment has its
.Em canmount
property set to
.Em noauto
and its
.Em mountpoint
property set to
.Pa / Ns .
.It Xo
.Cm create
.Ar beName@snapshot
.Xc
Rather than creating a new boot environment, this just creates a snapshot of a
boot environment.
For instance, if the parent of the BE datasets is
.Pa zroot/ROOT Ns , then
.Sy bemgr\ foo@bar
would take a snapshot of
.Pa zroot/ROOT/foo
which was
.Pa zroot/ROOT/foo@bar Ns . So,
.Sy bemgr\ create\ foo@bar
would be equivalent to
.Sy zfs\ snap\ zroot/ROOT/foo@bar Ns .
.It Xo
.Cm destroy
.Op Fl k
.Op Fl n
.Op Fl F
.Ar beName
.Xc
This destroys the given boot environment (and its origin if it has one, and no
other dataset has the same origin).
.Pp
.Fl n
tells
.Sy bemgr
to do a dry\-run, so insted of actually destroying anything, it simply prints
out what would have been promoted or destroyed if
.Fl n
hadn't been used.
.Pp
Note that there is no confirmation.
So, anyone feeling paranoid about making sure that they're destroying what they
intend to should use
.Fl n
to verify, but without it,
.Sy bemgr\ destroy
will just destroy what it's supposed to without nagging about stuff like
whether the origin should be destroyed.
.Pp
.Fl k
tells
.Nm
to keep the origin in the case where the BE dataset is a clone; otherwise, it
will be destroyed as long as it is not the origin of another dataset.
.Pp
Normally, if any of what's being destroyed is mounted, it will be unmounted and
destroyed without a problem, but if it's actively in use, then zfs may refuse to
unmount it.
.Fl F
can be used to forcefully unmount what's being destroyed if that occurs (or you
can unmount it first). Of course, normally, inactive datasets are not mounted,
and
.Nm
will refuse to destroy a dataset if it's active.
So,
.Sy bemgr\ destroy
can't be used to destroy the currently running OS.
.Pp
In more detail:
.Bl -enum -width 1
.It
If any of the boot environment's snapshots are the origin of another dataset
(i.e. a dataset is a clone of that snapshot), then a clone of the newest
snapshot which has a clone will be promoted, shifting that origin snapshot and
the other snapshots which are older than it to the clone that's promoted,
meaning that they will not be destroyed.
.It
If the boot environment has an origin (and thus is a clone), and that origin
snapshot is not the origin of another dataset, then that origin snapshot will
be destroyed.
.It
The dataset itself and any of its remaining snapshots will be destroyed.
.El
.Pp
So,
.Nm
destroys what it destroys without confirmation \- including the origin snapshot
of the given dataset \- but it promotes clones where necessary so that the BE
that it was told to destroy can be destroyed without destroying any other
datasets.
The idea is that no cruft will be left behind, and the user will not be nagged,
but
.Fl n
provides a way to preview the results if desired.
.It Xo
.Cm destroy
.Op Fl n
.Op Fl F
.Ar beName@snapshot
.Xc
This will destroy the given snapshot.
So, if
.Pa zroot/ROOT
is the parent dataset of the BEs, then
.Sy bemgr\ destroy\ foo@bar
will destroy
.Pa zroot/ROOT/foo@bar
and would be equivalent to
.Sy zfs\ destroy\ zroot/ROOT/foo@bar Ns .
.Pp
If the given snapshot is the origin of another dataset, then an error will be
printed out, and nothing will be destroyed.
.Pp
.Fl n
tells
.Nm
to do a dry\-run, so instead of actually destroying anything, it simply prints
out what would have been destroyed if
.Fl n
hadn't been used.
.Pp
Normally, if any of what's being destroyed is mounted, it will be unmounted and
destroyed without a problem, but if it's actively in use, then zfs may refuse
to unmount it.
.Fl F
can be used to forcefully unmount what's being destroyed if that occurs (or you
can unmount it first).
Of course, normally, snapshots are not mounted.
.It Xo
.Cm export
.Op Fl k
.Op Fl v
.Ar sourceBE
.Xc
Takes a snapshot of the given BE and does
.Sy zfs\ send
on it to
.Em stdout
so that it can be piped or redirected to a file, or to
.Sy ssh Ns ,
etc.
.Pp
.Fl k
makes it so that the snapshot is kept after the export has completed;
otherwise, the snapshot will be destroyed.
.Pp
.Fl v
makes the output verbose.
.It Xo
.Cm import
.Op Fl v
.Ar targetBE
.Xc
Takes a dataset from
.Em stdin
(presumably having been read from a file or
.Sy ssh Ns )
which is then used with
.Sy zfs\ recv
to create a new boot environment with the given name.
.Pp
.Fl v
makes the output verbose, though
.Sy zfs\ recv
doesn't print out much with
.Fl v Ns .
.Sy zfs\ send
is the end that gets the output that actually indicates the progress of the
stream, so
.Sy bemgr\ export\ \-v
has much more useful output than
.Sy bemgr\ import\ \-v
does.
.Pp
As with any new boot environment, the newly created BE has its
.Em canmount
property set to
.Em noauto
and its
.Em mountpoint
property set to
.Pa / Ns .
.It Xo
.Cm list
.Op Fl H
.Xc
This lists out the existing boot environments, sorted by their creation time.
.Pp
.Fl H
is used for scripting.
It replaces all of the spaces between columns with a single tab character.
It also removes the column headers.
.Pp
e.g.
.Sy bemgr list
.Bd -literal
BE                                 Active  Mountpoint    Space  Referenced  If Last  Created
2024\-12\-15_update                  \-       \-           562.95M      53.81G    61.3G  2024\-12\-15 20:57:18
2025\-01\-04_update                  \-       \-           737.47M      54.06G   61.55G  2025\-01\-04 02:48:02
2025\-02\-04_update                  \-       \-           698.62M      56.66G   64.15G  2025\-02\-04 19:22:18
14.1\-RELEASE\-p6_2025\-02\-09_094839  \-       \-             1.19M      57.07G   64.56G  2025\-02\-09 09:48:39
2025\-02\-09_freebsd14_2             \-       \-             1.94M      57.07G   64.56G  2025\-02\-09 17:00:25
14.2\-RELEASE\-p1_2025\-02\-09_181633  \-       \-             2.01M      58.22G   65.71G  2025\-02\-09 18:16:33
default                            NR      /            75.18G      59.04G   66.64G  2025\-03\-03 00:44:23
2025\-03\-29_update                  \-       \-              236K      59.03G    66.6G  2025\-03\-29 18:27:05
.Ed
.Pp
.Sy Columns
.Bl -tag -width 1234567890
.It BE
The name of the boot environment
.It Active
The active boot environment is the one that's mounted as root.
.Sy Dq \-
means that that BE is inactive.
.Sy Dq N
means that that BE is the active boot environment now, and
.Sy Dq R
means that it will be the active boot environment when the system is next
rebooted.
.It Mountpoint
The current mountpoint of the BE.
.Sy Dq \-
means that that boot environment is not currently mounted and does not say
anything about the
.Em mountpoint
property of the dataset (normally, that's always
.Pa /
for a BE's dataset).
.Pp
The currently active BE will show
.Pa /
as its mountpoint, and any other BE which shows a mountpoint other than
.Sy Dq \-
will be showing its current mountpoint and not the
.Em mountpoint
property of the dataset.
Normally, no BEs other than the currently active one will be mounted, but it is
possible to mount them using
.Sy bemgr\ mount
or via
.Sy mount Ns .
.It Space
For BEs whose dataset is not a clone, this is equivalent to the
.Em used
property of the dataset. For BEs whose dataset is a clone of a snapshot, it's
equivalent to the
.Em used
property of the dataset + the
.Em used
property of the origin snapshot.
.It Reference
This is equivalent to the
.Em referenced
property of the BE's dataset.
.It If Last
This is the amount of space that the BE is calculated to take up if
all of the other BE's are destroyed.
.Pp
In specific, if the BE's dataset is not a clone, then it's the total of the
.Em usedbydataset
property of the BE's dataset, the
.Em usedbyrefreservation
property of the BE's dataset, and the
.Em used
property of any of its snapshots which are not the origin of another BE's
dataset (since
.Sy bemgr\ destroy
destroys the origin snapshot for a BE when it
destroys that BE).
So, it's equivalent to the
.Em used
property of the dataset minus the space for its snapshots which are the origin
of another BE's dataset.
.Pp
If the BE's dataset is a clone, then the calculation is the same but under the
assumption that it's promoted first (which would move some snapshots currently
under another dataset to the dataset being promoted, since the origin snapshot
and snapshots older than the origin snapshot get moved to the dataset being
promoted when it's promoted).
So, some snapshots besides the origin or those currently on that dataset could
be included.
But regardless, no snapshots which are the origin of another BE's dataset are
included in
.Em If Last
for any BE, since those snapshots are destroyed when
.Sy bemgr destroy
is used on those BEs.
.It Created
This is the
.Em creation
property of the BE's dataset, which gives the date/time that the BE was created.
.El
.Pp
.It Xo
.Cm list
.Fl a
.Op Fl H
.Op Fl s
.Xc
.Sy bemgr\ \-a
lists out the existing boot environments, sorted by their creation
time, but it also lists out the dataset for each BE and the origin for each BE
(if it has one).
If
.Fl s
is provided, then the snapshots are also listed
.Pf ( Fl s
implies
.Fl a Ns ,
so if it's used on its own, it's equivalent to
.Fl as Ns ).
.Pp
.Fl H
is used for scripting.
It replaces all of the spaces between columns with a single tab character.
It also removes the column headers.
.Pp
e.g.
.Sy bemgr\ list\ \-a
.Bd -literal
BE/Dataset/Snapshot                             Active  Mountpoint    Space  Referenced  Created

2024\-12\-15_update
  zroot/ROOT/2024\-12\-15_update                  \-       \-           562.95M      53.81G  2024\-12\-15 20:57:18
    zroot/ROOT/default@2024\-12\-15\-20:57:18      \-       \-           562.94M      53.81G  2024\-12\-15 20:57:18

2025\-01\-04_update
  zroot/ROOT/2025\-01\-04_update                  \-       \-           737.47M      54.06G  2025\-01\-04 02:48:02
    zroot/ROOT/default@2025\-01\-04\-02:48:02      \-       \-           737.46M      54.06G  2025\-01\-04 02:48:02

2025\-02\-04_update
  zroot/ROOT/2025\-02\-04_update                  \-       \-           698.62M      56.66G  2025\-02\-04 19:22:18
    zroot/ROOT/default@2025\-02\-04\-19:22:18      \-       \-           698.61M      56.66G  2025\-02\-04 19:22:18

14.1\-RELEASE\-p6_2025\-02\-09_094839
  zroot/ROOT/14.1\-RELEASE\-p6_2025\-02\-09_094839  \-       \-             1.19M      57.07G  2025\-02\-09 09:48:39
    zroot/ROOT/default@2025\-02\-09\-09:48:39\-0    \-       \-             1.19M      57.07G  2025\-02\-09 09:48:39

2025\-02\-09_freebsd14_2
  zroot/ROOT/2025\-02\-09_freebsd14_2             \-       \-             1.94M      57.07G  2025\-02\-09 17:00:25
    zroot/ROOT/default@2025\-02\-09\-17:00:24      \-       \-             1.93M      57.07G  2025\-02\-09 17:00:24

14.2\-RELEASE\-p1_2025\-02\-09_181633
  zroot/ROOT/14.2\-RELEASE\-p1_2025\-02\-09_181633  \-       \-             2.01M      58.22G  2025\-02\-09 18:16:33
    zroot/ROOT/default@2025\-03\-03\-00:44:23      \-       \-             1.32M      58.22G  2025\-03\-03 00:44:23

default
  zroot/ROOT/default                            NR      /            75.18G      59.04G  2025\-03\-03 00:44:23

2025\-03\-29_update
  zroot/ROOT/2025\-03\-29_update                  \-       \-              236K      59.03G  2025\-03\-29 18:27:05
    zroot/ROOT/default@2025\-03\-29\-18:27:05\-0    \-       \-              228K      59.03G  2025\-03\-29 18:27:05
.Ed
.Pp
e.g.
.Sy bemgr\ list\ \-as
.Bd -literal
BE/Dataset/Snapshot                                           Active  Mountpoint    Space  Referenced  Created

2024\-12\-15_update
  zroot/ROOT/2024\-12\-15_update                                \-       \-           562.95M      53.81G  2024\-12\-15 20:57:18
    zroot/ROOT/default@2024\-12\-15\-20:57:18                    \-       \-           562.94M      53.81G  2024\-12\-15 20:57:18

2025\-01\-04_update
  zroot/ROOT/2025\-01\-04_update                                \-       \-           737.47M      54.06G  2025\-01\-04 02:48:02
    zroot/ROOT/default@2025\-01\-04\-02:48:02                    \-       \-           737.46M      54.06G  2025\-01\-04 02:48:02

2025\-02\-04_update
  zroot/ROOT/2025\-02\-04_update                                \-       \-           698.62M      56.66G  2025\-02\-04 19:22:18
    zroot/ROOT/default@2025\-02\-04\-19:22:18                    \-       \-           698.61M      56.66G  2025\-02\-04 19:22:18

14.1\-RELEASE\-p6_2025\-02\-09_094839
  zroot/ROOT/14.1\-RELEASE\-p6_2025\-02\-09_094839                \-       \-             1.19M      57.07G  2025\-02\-09 09:48:39
    zroot/ROOT/default@2025\-02\-09\-09:48:39\-0                  \-       \-             1.19M      57.07G  2025\-02\-09 09:48:39

2025\-02\-09_freebsd14_2
  zroot/ROOT/2025\-02\-09_freebsd14_2                           \-       \-             1.94M      57.07G  2025\-02\-09 17:00:25
    zroot/ROOT/default@2025\-02\-09\-17:00:24                    \-       \-             1.93M      57.07G  2025\-02\-09 17:00:24

14.2\-RELEASE\-p1_2025\-02\-09_181633
  zroot/ROOT/14.2\-RELEASE\-p1_2025\-02\-09_181633                \-       \-             2.01M      58.22G  2025\-02\-09 18:16:33
    zroot/ROOT/default@2025\-03\-03\-00:44:23                    \-       \-             1.32M      58.22G  2025\-03\-03 00:44:23

default
  zroot/ROOT/default                                          NR      /            75.18G      59.04G  2025\-03\-03 00:44:23
  zroot/ROOT/default@2024\-12\-15\-20:57:18                      \-       \-           562.94M      53.81G  2024\-12\-15 20:57:18
  zroot/ROOT/default@2025\-01\-04\-02:48:02                      \-       \-           737.46M      54.06G  2025\-01\-04 02:48:02
  zroot/ROOT/default@2025\-02\-04\-19:22:18                      \-       \-           698.61M      56.66G  2025\-02\-04 19:22:18
  zroot/ROOT/default@2025\-02\-09\-09:48:39\-0                    \-       \-             1.19M      57.07G  2025\-02\-09 09:48:39
  zroot/ROOT/default@2025\-02\-09\-17:00:24                      \-       \-             1.93M      57.07G  2025\-02\-09 17:00:24
  zroot/ROOT/default@2025\-03\-03\-00:44:23                      \-       \-             1.32M      58.22G  2025\-03\-03 00:44:23
  zroot/ROOT/default@zfs\-auto\-snap_daily\-2025\-03\-28\-05h07     \-       \-            88.02M      59.03G  2025\-03\-28 05:07:01
  zroot/ROOT/default@zfs\-auto\-snap_daily\-2025\-03\-29\-05h07     \-       \-             2.95M      59.03G  2025\-03\-29 05:07:01
  zroot/ROOT/default@2025\-03\-29\-18:27:05\-0                    \-       \-              228K      59.03G  2025\-03\-29 18:27:05
  zroot/ROOT/default@zfs\-auto\-snap_daily\-2025\-03\-30\-05h07     \-       \-             1.17M      58.96G  2025\-03\-30 05:07:01
  zroot/ROOT/default@zfs\-auto\-snap_daily\-2025\-03\-31\-05h07     \-       \-             2.53M      58.97G  2025\-03\-31 05:07:01
  zroot/ROOT/default@zfs\-auto\-snap_daily\-2025\-04\-01\-05h07     \-       \-             1.25M      58.95G  2025\-04\-01 05:07:01
  zroot/ROOT/default@zfs\-auto\-snap_daily\-2025\-04\-02\-05h07     \-       \-              724K      58.96G  2025\-04\-02 05:07:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-02\-15h00    \-       \-              496K      58.96G  2025\-04\-02 15:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-02\-16h00    \-       \-              416K      58.96G  2025\-04\-02 16:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-02\-17h00    \-       \-              424K      58.96G  2025\-04\-02 17:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-02\-18h00    \-       \-              492K      58.96G  2025\-04\-02 18:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-02\-19h00    \-       \-              908K      58.96G  2025\-04\-02 19:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-02\-20h00    \-       \-              392K      58.96G  2025\-04\-02 20:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-02\-21h00    \-       \-              392K      58.96G  2025\-04\-02 21:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-02\-22h00    \-       \-              400K      58.96G  2025\-04\-02 22:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-02\-23h00    \-       \-              408K      58.96G  2025\-04\-02 23:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-03\-00h00    \-       \-              384K      58.96G  2025\-04\-03 00:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-03\-01h00    \-       \-              384K      58.96G  2025\-04\-03 01:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-03\-02h00    \-       \-              464K      58.96G  2025\-04\-03 02:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-03\-03h00    \-       \-              552K      58.96G  2025\-04\-03 03:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-03\-04h00    \-       \-              676K      58.96G  2025\-04\-03 04:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-03\-05h00    \-       \-              288K      58.96G  2025\-04\-03 05:00:01
  zroot/ROOT/default@zfs\-auto\-snap_daily\-2025\-04\-03\-05h07     \-       \-              352K      58.96G  2025\-04\-03 05:07:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-03\-06h00    \-       \-              392K      58.96G  2025\-04\-03 06:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-03\-07h00    \-       \-              368K      58.96G  2025\-04\-03 07:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-03\-08h00    \-       \-              408K      58.96G  2025\-04\-03 08:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-03\-09h00    \-       \-              424K      58.96G  2025\-04\-03 09:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-03\-10h00    \-       \-              392K      58.96G  2025\-04\-03 10:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-03\-11h00    \-       \-              384K      58.96G  2025\-04\-03 11:00:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-03\-12h00    \-       \-              468K      58.96G  2025\-04\-03 12:00:32
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-03\-13h00    \-       \-                0B      59.04G  2025\-04\-03 13:00:01
  zroot/ROOT/default@zfs\-auto\-snap_frequent\-2025\-04\-03\-13h05  \-       \-                0B      59.04G  2025\-04\-03 13:05:01
  zroot/ROOT/default@zfs\-auto\-snap_frequent\-2025\-04\-03\-13h10  \-       \-              104K      59.04G  2025\-04\-03 13:10:01
  zroot/ROOT/default@zfs\-auto\-snap_frequent\-2025\-04\-03\-13h15  \-       \-              104K      59.04G  2025\-04\-03 13:15:01
  zroot/ROOT/default@zfs\-auto\-snap_frequent\-2025\-04\-03\-13h20  \-       \-              104K      59.04G  2025\-04\-03 13:20:01
  zroot/ROOT/default@zfs\-auto\-snap_frequent\-2025\-04\-03\-13h25  \-       \-                0B      59.04G  2025\-04\-03 13:25:01
  zroot/ROOT/default@zfs\-auto\-snap_frequent\-2025\-04\-03\-13h30  \-       \-                0B      59.04G  2025\-04\-03 13:30:01
  zroot/ROOT/default@zfs\-auto\-snap_frequent\-2025\-04\-03\-13h35  \-       \-                0B      59.04G  2025\-04\-03 13:35:01
  zroot/ROOT/default@zfs\-auto\-snap_frequent\-2025\-04\-03\-13h40  \-       \-                0B      59.04G  2025\-04\-03 13:40:01
  zroot/ROOT/default@zfs\-auto\-snap_frequent\-2025\-04\-03\-13h45  \-       \-                0B      59.04G  2025\-04\-03 13:45:01
  zroot/ROOT/default@zfs\-auto\-snap_frequent\-2025\-04\-03\-13h50  \-       \-                0B      59.04G  2025\-04\-03 13:50:01
  zroot/ROOT/default@zfs\-auto\-snap_frequent\-2025\-04\-03\-13h55  \-       \-              104K      59.04G  2025\-04\-03 13:55:01
  zroot/ROOT/default@zfs\-auto\-snap_hourly\-2025\-04\-03\-14h00    \-       \-              104K      59.04G  2025\-04\-03 14:00:01
  zroot/ROOT/default@zfs\-auto\-snap_frequent\-2025\-04\-03\-14h05  \-       \-              128K      59.04G  2025\-04\-03 14:05:01
  zroot/ROOT/default@zfs\-auto\-snap_frequent\-2025\-04\-03\-14h10  \-       \-                0B      59.04G  2025\-04\-03 14:10:01

2025\-03\-29_update
  zroot/ROOT/2025\-03\-29_update                                \-       \-              236K      59.03G  2025\-03\-29 18:27:05
    zroot/ROOT/default@2025\-03\-29\-18:27:05\-0                  \-       \-              228K      59.03G  2025\-03\-29 18:27:05
.Ed
.Pp
The columns are basically the same as with
.Sy bemgr\ list
without
.Fl a
except that there is no
.Em If Last Ns .
However, the column for names is obviously slightly different. In the case of
.Bd -literal
2025\-02\-04_update
  zroot/ROOT/2025\-02\-04_update                                \-       \-           698.62M      56.66G  2025\-02\-04 19:22:18
    zroot/ROOT/default@2025\-02\-04\-19:22:18                    \-       \-           698.61M      56.66G  2025\-02\-04 19:22:18
.Ed
.Pp
.Pa 2025\-02\-04_update
is the BE name,
.Pa zroot/ROOT/2025\-02\-04_update
is the dataset for that BE, and
.Pa zroot/ROOT/default@2025\-02\-04\-19:22:18
is the origin snapshot of that dataset.
Since the dataset has no snapshots of
its own, that's the entire list even with
.Fl s Ns ,
whereas if it had additional snapshots, they'd be listed after the origin.
For instance, if
.Em 2025\-02\-04_update
were activated (and thus its dataset was promoted), then its output from
.Sy bemgr\ list\ \-as
would become
.Bd -literal
2025\-02\-04_update
  zroot/ROOT/2025\-02\-04_update                                \-       \-            70.02G      56.66G  2025\-02\-04 19:22:18
  zroot/ROOT/2025\-02\-04_update@2024\-12\-15\-20:57:18            \-       \-           562.94M      53.81G  2024\-12\-15 20:57:18
  zroot/ROOT/2025\-02\-04_update@2025\-01\-04\-02:48:02            \-       \-           737.46M      54.06G  2025\-01\-04 02:48:02
  zroot/ROOT/2025\-02\-04_update@2025\-02\-04\-19:22:18            \-       \-                8K      56.66G  2025\-02\-04 19:22:18
.Ed
.Pp
since the origin snapshot and the snapshots older than it would be moved to
.Pa zroot/ROOT/2025\-02\-04_update
when it's promoted.
.It Xo
.Cm mount
.Ar beName
.Ar mountpoint
.Xc
This mounts the given boot environment at the given mountpoint. It has no
effect on the
.Em mountpoint
property of the dataset.
It's intended for use cases where you need to access the contents of a boot
environment without actually booting it.
.Pp
For instance, if the parent dataset of the BEs is
.Pa zroot/ROOT Ns ,
then
.Sy bemgr\ mount\ foo\ /mnt
would be equivalent to
.Sy mount\ \-t\ zfs\ zroot/ROOT/foo\ /mnt
on FreeBSD or
.Sy mount\ \-t\ zfs\ \-o\ zfsutil\ zroot/ROOT/foo\ /mnt
on Linux.
.Pp
The mountpoint must exist.
.It Xo
.Cm rename
.Ar origBEName
.Ar newBEName
.Xc
This renames the given boot environment.
It has no effect on mounting.
.Pp
For instance, if the parent dataset of the BEs is
.Pa zroot/ROOT Ns ,
then
.Sy bemgr\ rename\ foo\ bar
would be equivalent to
.Sy zfs\ rename\ \-u\ zroot/ROOT/foo\ zroot/ROOT/bar Ns .
.Pp
In addition, if the BE in the
.Sy bootfs
zpool property is the one that's renamed (i.e. the BE that will be active when
the system next boots), then the
.Sy bootfs
zpool property is updated accordingly.
.It Xo
.Cm umount
.Op Fl f
.Ar beName
.Xc
.It Xo
.Cm unmount
.Op Fl f
.Ar beName
.Xc
This unmounts the given boot environment (but will not work on the currently
active boot environment).
.Pp
For instance, if the parent dataset of the BEs is
.Pa zroot/ROOT Ns ,
then
.Sy bemgr\ umount\ foo
would be equivalent to
.Sy zfs\ unmount\ zroot/ROOT/foo Ns .
.Pp
On FreeBSD,
.Fl f
causes the dataset to be unmounted even if it's busy.
On Linux,
.Fl f
is not supported, because
.Sy zfs\ umount
on Linux does not support forcefully unmounting datasets.
.El
.Sh Boot Managers
.Nm
does nothing special to support any specific boot managers.
Rather, it will work with any boot manager which is designed to work with
standard ZFS boot environments.
On FreeBSD, it works with FreeBSD's normal boot manager.
On Linux, it works with zfsbootmenu.
It's possible that it will work with other boot managers as well, but they need
to work with no support from
.Nm Ns .
.Pp
.Sy rEFInd
can be used in dual\-boot environments, since it will forward to other boot
managers such as the FreeBSD boot manager, zfsbootmenu, or Windows' boot
manager.
.Sh SEE ALSO
.Xr zfs 8
.Xr zfsprops 7
.Xr zpool 8
.Sh HISTORY
.Nm
is modeled after
.Xr bectl 8 and
.Xr beadm 8 , which are great programs for managing boot environments on FreeBSD
but do not support Linux.
So,
.Nm
was written to have a similar solution on Linux but was made to work on both
FreeBSD and Linux.
.Sh AUTHORS
.Nm
was written by
.An Jonathan M Davis Aq Mt jmdavis@jmdavisprog.com .
